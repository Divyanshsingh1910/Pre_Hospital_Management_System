{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epuN41MvnQH2",
        "outputId": "cc7f240b-a975-43cf-bbc2-532631e005df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/hzwer/arXiv2020-RIFE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e92rFz56nS-f",
        "outputId": "f814d0d5-37db-49bf-a169-329d0cc589a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'arXiv2020-RIFE'...\n",
            "remote: Enumerating objects: 1935, done.\u001b[K\n",
            "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 1935 (delta 14), reused 1 (delta 0), pack-reused 1908\u001b[K\n",
            "Receiving objects: 100% (1935/1935), 4.09 MiB | 19.14 MiB/s, done.\n",
            "Resolving deltas: 100% (1222/1222), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/arXiv2020-RIFE/train_log\n",
        "%cd /content/arXiv2020-RIFE/train_log\n",
        "!gdown --id 1APIzVeI-4ZZCEuIRE1m6WYfSCaOsi_7_\n",
        "!7z e RIFE_trained_model_v3.6.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKnv4o2upI0y",
        "outputId": "88a689d0-f6cf-471f-e973-4c3250a7363f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/arXiv2020-RIFE/train_log\n",
            "/usr/local/lib/python3.9/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1APIzVeI-4ZZCEuIRE1m6WYfSCaOsi_7_\n",
            "To: /content/arXiv2020-RIFE/train_log/RIFE_trained_model_v3.6.zip\n",
            "100% 11.3M/11.3M [00:00<00:00, 27.9MB/s]\n",
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.30GHz (306F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 11332064 bytes (11 MiB)\n",
            "\n",
            "Extracting archive: RIFE_trained_model_v3.6.zip\n",
            "--\n",
            "Path = RIFE_trained_model_v3.6.zip\n",
            "Type = zip\n",
            "Physical Size = 11332064\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\bEverything is Ok\n",
            "\n",
            "Folders: 4\n",
            "Files: 10\n",
            "Size:       12208819\n",
            "Compressed: 11332064\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/arXiv2020-RIFE/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puK1Kzx3qO4Z",
        "outputId": "4ca34705-9b6a-40f9-fbd5-2701b23878b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/arXiv2020-RIFE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AguagnblqO3B",
        "outputId": "45118fa3-dbbe-4def-da07-72484ae41346"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 1)) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.35.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 2)) (4.65.0)\n",
            "Collecting sk-video>=1.1.10\n",
            "  Downloading sk_video-1.1.10-py2.py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch==1.7.1\n",
            "  Downloading torch-1.7.1-cp39-cp39-manylinux1_x86_64.whl (776.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.8/776.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 5)) (4.7.0.72)\n",
            "Requirement already satisfied: moviepy>=1.0.3 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 6)) (1.0.3)\n",
            "Collecting torchvision==0.8.2\n",
            "  Downloading torchvision-0.8.2-cp39-cp39-manylinux1_x86_64.whl (12.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m98.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.7.1->-r requirements.txt (line 4)) (4.5.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.9/dist-packages (from torchvision==0.8.2->-r requirements.txt (line 7)) (8.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from sk-video>=1.1.10->-r requirements.txt (line 3)) (1.10.1)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.9/dist-packages (from moviepy>=1.0.3->-r requirements.txt (line 6)) (0.1.10)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.9/dist-packages (from moviepy>=1.0.3->-r requirements.txt (line 6)) (4.4.2)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from moviepy>=1.0.3->-r requirements.txt (line 6)) (2.27.1)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.9/dist-packages (from moviepy>=1.0.3->-r requirements.txt (line 6)) (0.4.8)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.9/dist-packages (from moviepy>=1.0.3->-r requirements.txt (line 6)) (2.25.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.3->-r requirements.txt (line 6)) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.3->-r requirements.txt (line 6)) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.3->-r requirements.txt (line 6)) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0,>=2.8.1->moviepy>=1.0.3->-r requirements.txt (line 6)) (1.26.15)\n",
            "Installing collected packages: torch, torchvision, sk-video\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.0+cu118\n",
            "    Uninstalling torch-2.0.0+cu118:\n",
            "      Successfully uninstalled torch-2.0.0+cu118\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.15.1+cu118\n",
            "    Uninstalling torchvision-0.15.1+cu118:\n",
            "      Successfully uninstalled torchvision-0.15.1+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.15.1 requires torch==2.0.0, but you have torch 1.7.1 which is incompatible.\n",
            "torchdata 0.6.0 requires torch==2.0.0, but you have torch 1.7.1 which is incompatible.\n",
            "torchaudio 2.0.1+cu118 requires torch==2.0.0, but you have torch 1.7.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed sk-video-1.1.10 torch-1.7.1 torchvision-0.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imageio-ffmpeg\n",
        "!pip3 install ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZTWbNdMqnJV",
        "outputId": "d226f102-86de-4f92-9d9b-568faaceee16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.10/dist-packages (0.4.8)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ffmpeg\n",
            "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: ffmpeg\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6083 sha256=8c8765e4693509dc3c31362d93327c142282b11d46dad6c76df60d7b2c77a04d\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/7a/69/cd6aeb83b126a7f04cbe7c9d929028dc52a6e7d525ff56003a\n",
            "Successfully built ffmpeg\n",
            "Installing collected packages: ffmpeg\n",
            "Successfully installed ffmpeg-1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.system('ffmpeg -y -i \"/content/drive/MyDrive/Video_/Ambulance_Videos/VIDEOS/00M48S_1675510248.mp4\" -vcodec libx265 -x265-params \"crf=45\" -r 3 -vf \"scale=trunc(iw/2):trunc(ih/2), mpdecimate\" \"/content/output56.mp4\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgUMDg_Dq3Y1",
        "outputId": "8ec993d4-4113-4638-8f5e-d367e84dfcf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/isaaccorley/pytorch-enhance\n",
        "%cd pytorch-enhance\n",
        "!python setup.py install\n",
        "!pip install poutyne\n",
        "! pip install scikit-video"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkcPCIpOuqYL",
        "outputId": "3e019761-c7db-45b7-cc73-837915b141eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'pytorch-enhance'...\n",
            "remote: Enumerating objects: 972, done.\u001b[K\n",
            "remote: Counting objects: 100% (188/188), done.\u001b[K\n",
            "remote: Compressing objects: 100% (76/76), done.\u001b[K\n",
            "remote: Total 972 (delta 109), reused 163 (delta 106), pack-reused 784\u001b[K\n",
            "Receiving objects: 100% (972/972), 29.78 MiB | 29.98 MiB/s, done.\n",
            "Resolving deltas: 100% (579/579), done.\n",
            "/content/pytorch-enhance\n",
            "/usr/local/lib/python3.9/dist-packages/setuptools/dist.py:788: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/setuptools/__init__.py:85: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated. Requirements should be satisfied by a PEP 517 installer. If you are using pip, you can try `pip install --use-pep517`.\n",
            "  dist.fetch_build_eggs(dist.setup_requires)\n",
            "/usr/local/lib/python3.9/dist-packages/setuptools/dist.py:788: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
            "  warnings.warn(\n",
            "running install\n",
            "/usr/local/lib/python3.9/dist-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/setuptools/command/easy_install.py:144: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n",
            "  warnings.warn(\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating torch_enhance.egg-info\n",
            "writing torch_enhance.egg-info/PKG-INFO\n",
            "writing dependency_links to torch_enhance.egg-info/dependency_links.txt\n",
            "writing requirements to torch_enhance.egg-info/requires.txt\n",
            "writing top-level names to torch_enhance.egg-info/top_level.txt\n",
            "writing manifest file 'torch_enhance.egg-info/SOURCES.txt'\n",
            "reading manifest file 'torch_enhance.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'torch_enhance.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/torch_enhance\n",
            "copying torch_enhance/metrics.py -> build/lib/torch_enhance\n",
            "copying torch_enhance/utils.py -> build/lib/torch_enhance\n",
            "copying torch_enhance/__init__.py -> build/lib/torch_enhance\n",
            "creating build/lib/tests\n",
            "copying tests/test_models.py -> build/lib/tests\n",
            "copying tests/__init__.py -> build/lib/tests\n",
            "copying tests/test_datasets.py -> build/lib/tests\n",
            "creating build/lib/torch_enhance/models\n",
            "copying torch_enhance/models/base.py -> build/lib/torch_enhance/models\n",
            "copying torch_enhance/models/espcn.py -> build/lib/torch_enhance/models\n",
            "copying torch_enhance/models/edsr.py -> build/lib/torch_enhance/models\n",
            "copying torch_enhance/models/__init__.py -> build/lib/torch_enhance/models\n",
            "copying torch_enhance/models/vdsr.py -> build/lib/torch_enhance/models\n",
            "copying torch_enhance/models/baseline.py -> build/lib/torch_enhance/models\n",
            "copying torch_enhance/models/srresnet.py -> build/lib/torch_enhance/models\n",
            "copying torch_enhance/models/srcnn.py -> build/lib/torch_enhance/models\n",
            "creating build/lib/torch_enhance/losses\n",
            "copying torch_enhance/losses/vgg.py -> build/lib/torch_enhance/losses\n",
            "copying torch_enhance/losses/__init__.py -> build/lib/torch_enhance/losses\n",
            "creating build/lib/torch_enhance/datasets\n",
            "copying torch_enhance/datasets/bsds100.py -> build/lib/torch_enhance/datasets\n",
            "copying torch_enhance/datasets/bsds300.py -> build/lib/torch_enhance/datasets\n",
            "copying torch_enhance/datasets/bsds500.py -> build/lib/torch_enhance/datasets\n",
            "copying torch_enhance/datasets/base.py -> build/lib/torch_enhance/datasets\n",
            "copying torch_enhance/datasets/urban100.py -> build/lib/torch_enhance/datasets\n",
            "copying torch_enhance/datasets/bsds200.py -> build/lib/torch_enhance/datasets\n",
            "copying torch_enhance/datasets/__init__.py -> build/lib/torch_enhance/datasets\n",
            "copying torch_enhance/datasets/historical.py -> build/lib/torch_enhance/datasets\n",
            "copying torch_enhance/datasets/t91.py -> build/lib/torch_enhance/datasets\n",
            "copying torch_enhance/datasets/general100.py -> build/lib/torch_enhance/datasets\n",
            "copying torch_enhance/datasets/set14.py -> build/lib/torch_enhance/datasets\n",
            "copying torch_enhance/datasets/div2k.py -> build/lib/torch_enhance/datasets\n",
            "copying torch_enhance/datasets/manga109.py -> build/lib/torch_enhance/datasets\n",
            "copying torch_enhance/datasets/set5.py -> build/lib/torch_enhance/datasets\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/torch_enhance\n",
            "copying build/lib/torch_enhance/metrics.py -> build/bdist.linux-x86_64/egg/torch_enhance\n",
            "creating build/bdist.linux-x86_64/egg/torch_enhance/models\n",
            "copying build/lib/torch_enhance/models/base.py -> build/bdist.linux-x86_64/egg/torch_enhance/models\n",
            "copying build/lib/torch_enhance/models/espcn.py -> build/bdist.linux-x86_64/egg/torch_enhance/models\n",
            "copying build/lib/torch_enhance/models/edsr.py -> build/bdist.linux-x86_64/egg/torch_enhance/models\n",
            "copying build/lib/torch_enhance/models/__init__.py -> build/bdist.linux-x86_64/egg/torch_enhance/models\n",
            "copying build/lib/torch_enhance/models/vdsr.py -> build/bdist.linux-x86_64/egg/torch_enhance/models\n",
            "copying build/lib/torch_enhance/models/baseline.py -> build/bdist.linux-x86_64/egg/torch_enhance/models\n",
            "copying build/lib/torch_enhance/models/srresnet.py -> build/bdist.linux-x86_64/egg/torch_enhance/models\n",
            "copying build/lib/torch_enhance/models/srcnn.py -> build/bdist.linux-x86_64/egg/torch_enhance/models\n",
            "creating build/bdist.linux-x86_64/egg/torch_enhance/losses\n",
            "copying build/lib/torch_enhance/losses/vgg.py -> build/bdist.linux-x86_64/egg/torch_enhance/losses\n",
            "copying build/lib/torch_enhance/losses/__init__.py -> build/bdist.linux-x86_64/egg/torch_enhance/losses\n",
            "copying build/lib/torch_enhance/utils.py -> build/bdist.linux-x86_64/egg/torch_enhance\n",
            "copying build/lib/torch_enhance/__init__.py -> build/bdist.linux-x86_64/egg/torch_enhance\n",
            "creating build/bdist.linux-x86_64/egg/torch_enhance/datasets\n",
            "copying build/lib/torch_enhance/datasets/bsds100.py -> build/bdist.linux-x86_64/egg/torch_enhance/datasets\n",
            "copying build/lib/torch_enhance/datasets/bsds300.py -> build/bdist.linux-x86_64/egg/torch_enhance/datasets\n",
            "copying build/lib/torch_enhance/datasets/bsds500.py -> build/bdist.linux-x86_64/egg/torch_enhance/datasets\n",
            "copying build/lib/torch_enhance/datasets/base.py -> build/bdist.linux-x86_64/egg/torch_enhance/datasets\n",
            "copying build/lib/torch_enhance/datasets/urban100.py -> build/bdist.linux-x86_64/egg/torch_enhance/datasets\n",
            "copying build/lib/torch_enhance/datasets/bsds200.py -> build/bdist.linux-x86_64/egg/torch_enhance/datasets\n",
            "copying build/lib/torch_enhance/datasets/__init__.py -> build/bdist.linux-x86_64/egg/torch_enhance/datasets\n",
            "copying build/lib/torch_enhance/datasets/historical.py -> build/bdist.linux-x86_64/egg/torch_enhance/datasets\n",
            "copying build/lib/torch_enhance/datasets/t91.py -> build/bdist.linux-x86_64/egg/torch_enhance/datasets\n",
            "copying build/lib/torch_enhance/datasets/general100.py -> build/bdist.linux-x86_64/egg/torch_enhance/datasets\n",
            "copying build/lib/torch_enhance/datasets/set14.py -> build/bdist.linux-x86_64/egg/torch_enhance/datasets\n",
            "copying build/lib/torch_enhance/datasets/div2k.py -> build/bdist.linux-x86_64/egg/torch_enhance/datasets\n",
            "copying build/lib/torch_enhance/datasets/manga109.py -> build/bdist.linux-x86_64/egg/torch_enhance/datasets\n",
            "copying build/lib/torch_enhance/datasets/set5.py -> build/bdist.linux-x86_64/egg/torch_enhance/datasets\n",
            "creating build/bdist.linux-x86_64/egg/tests\n",
            "copying build/lib/tests/test_models.py -> build/bdist.linux-x86_64/egg/tests\n",
            "copying build/lib/tests/__init__.py -> build/bdist.linux-x86_64/egg/tests\n",
            "copying build/lib/tests/test_datasets.py -> build/bdist.linux-x86_64/egg/tests\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torch_enhance/metrics.py to metrics.cpython-39.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torch_enhance/models/base.py to base.cpython-39.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torch_enhance/models/espcn.py to espcn.cpython-39.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torch_enhance/models/edsr.py to edsr.cpython-39.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torch_enhance/models/__init__.py to __init__.cpython-39.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torch_enhance/models/vdsr.py to vdsr.cpython-39.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torch_enhance/models/baseline.py to baseline.cpython-39.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torch_enhance/models/srresnet.py to srresnet.cpython-39.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torch_enhance/models/srcnn.py to srcnn.cpython-39.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torch_enhance/losses/vgg.py to vgg.cpython-39.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torch_enhance/losses/__init__.py to __init__.cpython-39.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torch_enhance/utils.py to utils.cpython-39.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torch_enhance/__init__.py to __init__.cpython-39.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torch_enhance/datasets/bsds100.py to bsds100.cpython-39.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torch_enhance/datasets/bsds300.py to bsds300.cpython-39.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torch_enhance/datasets/bsds500.py to bsds500.cpython-39.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torch_enhance/datasets/base.py to base.cpython-39.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torch_enhance/datasets/urban100.py to urban100.cpython-39.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torch_enhance/datasets/bsds200.py to bsds200.cpython-39.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torch_enhance/datasets/__init__.py to __init__.cpython-39.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torch_enhance/datasets/historical.py to historical.cpython-39.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torch_enhance/datasets/t91.py to t91.cpython-39.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torch_enhance/datasets/general100.py to general100.cpython-39.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torch_enhance/datasets/set14.py to set14.cpython-39.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torch_enhance/datasets/div2k.py to div2k.cpython-39.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torch_enhance/datasets/manga109.py to manga109.cpython-39.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torch_enhance/datasets/set5.py to set5.cpython-39.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/test_models.py to test_models.cpython-39.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/__init__.py to __init__.cpython-39.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/tests/test_datasets.py to test_datasets.cpython-39.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying torch_enhance.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying torch_enhance.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying torch_enhance.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying torch_enhance.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying torch_enhance.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating dist\n",
            "creating 'dist/torch_enhance-0.1.8-py3.9.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing torch_enhance-0.1.8-py3.9.egg\n",
            "Copying torch_enhance-0.1.8-py3.9.egg to /usr/local/lib/python3.9/dist-packages\n",
            "Adding torch-enhance 0.1.8 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.9/dist-packages/torch_enhance-0.1.8-py3.9.egg\n",
            "Processing dependencies for torch-enhance==0.1.8\n",
            "Searching for kornia\n",
            "Reading https://pypi.org/simple/kornia/\n",
            "Downloading https://files.pythonhosted.org/packages/3d/1a/359de937bcf3353d6a9e369aadc6946ce2f43c28ce3886383c22131f2597/kornia-0.6.11-py2.py3-none-any.whl#sha256=97bf856ab36ddac8dd249a359da34875aaf7d960b308c50f14d69d62053bf5a2\n",
            "Best match: kornia 0.6.11\n",
            "Processing kornia-0.6.11-py2.py3-none-any.whl\n",
            "Installing kornia-0.6.11-py2.py3-none-any.whl to /usr/local/lib/python3.9/dist-packages\n",
            "Adding kornia 0.6.11 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.9/dist-packages/kornia-0.6.11-py3.9.egg\n",
            "error: torch 1.7.1 is installed but torch>=1.9.1 is required by {'kornia'}\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting poutyne\n",
            "  Downloading Poutyne-1.15-py3-none-any.whl (210 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.9/210.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from poutyne) (1.22.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from poutyne) (1.7.1)\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->poutyne) (4.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from torchmetrics->poutyne) (23.1)\n",
            "Collecting torch\n",
            "  Downloading torch-2.0.0-cp39-cp39-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch->poutyne) (3.1.2)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch->poutyne) (1.11.1)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch->poutyne) (3.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch->poutyne) (2.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch->poutyne) (3.11.0)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->poutyne) (0.40.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->poutyne) (67.6.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->poutyne) (16.0.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->poutyne) (3.25.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch->poutyne) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch->poutyne) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch, torchmetrics, poutyne\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.7.1\n",
            "    Uninstalling torch-1.7.1:\n",
            "      Successfully uninstalled torch-1.7.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.8.2 requires torch==1.7.1, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 poutyne-1.15 torch-2.0.0 torchmetrics-0.11.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-video\n",
            "  Downloading scikit_video-1.1.11-py2.py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from scikit-video) (1.22.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from scikit-video) (8.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from scikit-video) (1.10.1)\n",
            "Installing collected packages: scikit-video\n",
            "Successfully installed scikit-video-1.1.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from poutyne.framework import Model\n",
        "\n",
        "from torch_enhance.datasets import BSDS300, Set14, Set5\n",
        "from torch_enhance.models import SRCNN\n",
        "from torch_enhance import metrics\n",
        "import torch_enhance\n",
        "\n",
        "\n",
        "scale_factor = 2\n",
        "# train_dataset = BSDS300(scale_factor=scale_factor)\n",
        "# val_dataset = Set14(scale_factor=scale_factor)\n",
        "# train_dataloader = DataLoader(train_dataset, batch_size=8)\n",
        "# val_dataloader = DataLoader(val_dataset, batch_size=2)\n",
        "\n",
        "# channels = 3 if train_dataset.color_space == \"RGB\" else 1\n",
        "pytorch_network = torch_enhance.models.ESPCN(scale_factor=2)\n",
        "\n",
        "model = Model(\n",
        "    pytorch_network,\n",
        "    'adam',\n",
        "    \"mse\"\n",
        ")\n",
        "path='/content/drive/My Drive/Models/super-res-amb.pt'\n",
        "model.load_weights(path)\n",
        "\n",
        "# model.fit_generator(\n",
        "#     train_dataloader,\n",
        "#     val_dataloader,\n",
        "#     epochs=1\n",
        "# )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Tm-ulTHuqKC",
        "outputId": "89bcc061-85f6-48ef-bf72-6e16e18920c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import skvideo.io\n",
        "import cv2\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "lN_6wydav24U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3INcBvkWuqCW",
        "outputId": "1f6e28d6-b4c2-47f6-e446-a9c5cac5b4c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "vid = skvideo.io.FFmpegReader('./output.mp4')\n",
        "write_f = skvideo.io.FFmpegWriter('./super-res.mp4',\n",
        "    inputdict={\n",
        "      '-r': '3',\n",
        "})\n",
        "\n",
        "shapex, shapey = 1920//4, 1080//4\n",
        "all_f=[]\n",
        "for frame in vid.nextFrame():\n",
        "  # print(frame.shape)\n",
        "  frame=cv2.resize(frame, (2*shapex//3, 2*shapey//3))\n",
        "  # all_f.append(frame)\n",
        "  frame=frame.transpose(2, 0, 1)/255\n",
        "  frame=torch.from_numpy(np.array(frame, dtype=np.float32))\n",
        "  frame=model.predict(frame, verbose=False).transpose(1, 2, 0)\n",
        "  arr=np.array(frame*255, dtype=np.int32)\n",
        "  arr[arr<0]=0\n",
        "  write_f.writeFrame(arr)\n",
        "  # print(arr)\n",
        "write_f.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCYY_KYjup_2",
        "outputId": "dc89e8ea-4476-4573-a77c-59bf48d3fe23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/arXiv2020-RIFE\n",
        "!python3 inference_video.py --exp=3 --video=\"../super-res.mp4\" --scale=0.5 --output=\"/content/drive/MyDrive/output_file.mp4\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0a9ojhzqZ2t",
        "outputId": "45e376eb-efe7-409a-a84e-6350d7f70ff2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/arXiv2020-RIFE\n",
            "Loaded v3.x HD model.\n",
            "../super-res.mp4, 182.0 frames in total, 3.0FPS to 24.0FPS\n",
            "The audio will be merged after interpolation process\n",
            " 99% 181/182.0 [00:18<00:00,  9.55it/s]\n",
            "ALSA lib confmisc.c:767:(parse_card) cannot find card '0'\n",
            "ALSA lib conf.c:4732:(_snd_config_evaluate) function snd_func_card_driver returned error: No such file or directory\n",
            "ALSA lib confmisc.c:392:(snd_func_concat) error evaluating strings\n",
            "ALSA lib conf.c:4732:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
            "ALSA lib confmisc.c:1246:(snd_func_refer) error evaluating name\n",
            "ALSA lib conf.c:4732:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
            "ALSA lib conf.c:5220:(snd_config_expand) Evaluate error: No such file or directory\n",
            "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM default\n",
            "ALSA lib confmisc.c:767:(parse_card) cannot find card '0'\n",
            "ALSA lib conf.c:4732:(_snd_config_evaluate) function snd_func_card_driver returned error: No such file or directory\n",
            "ALSA lib confmisc.c:392:(snd_func_concat) error evaluating strings\n",
            "ALSA lib conf.c:4732:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
            "ALSA lib confmisc.c:1246:(snd_func_refer) error evaluating name\n",
            "ALSA lib conf.c:4732:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
            "ALSA lib conf.c:5220:(snd_config_expand) Evaluate error: No such file or directory\n",
            "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM default\n",
            "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 31.100 / 56. 31.100\n",
            "  libavcodec     58. 54.100 / 58. 54.100\n",
            "  libavformat    58. 29.100 / 58. 29.100\n",
            "  libavdevice    58.  8.100 / 58.  8.100\n",
            "  libavfilter     7. 57.100 /  7. 57.100\n",
            "  libavresample   4.  0.  0 /  4.  0.  0\n",
            "  libswscale      5.  5.100 /  5.  5.100\n",
            "  libswresample   3.  5.100 /  3.  5.100\n",
            "  libpostproc    55.  5.100 / 55.  5.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '../super-res.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2avc1mp41\n",
            "    encoder         : Lavf58.29.100\n",
            "  Duration: 00:01:00.67, start: 0.000000, bitrate: 380 kb/s\n",
            "    Stream #0:0(und): Video: h264 (High 4:4:4 Predictive) (avc1 / 0x31637661), yuv444p, 640x360, 379 kb/s, 3 fps, 3 tbr, 12288 tbn, 6 tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : VideoHandler\n",
            "Output #0, matroska, to './temp/audio.mkv':\n",
            "\u001b[1;31mOutput file #0 does not contain any stream\n",
            "\u001b[0mffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 31.100 / 56. 31.100\n",
            "  libavcodec     58. 54.100 / 58. 54.100\n",
            "  libavformat    58. 29.100 / 58. 29.100\n",
            "  libavdevice    58.  8.100 / 58.  8.100\n",
            "  libavfilter     7. 57.100 /  7. 57.100\n",
            "  libavresample   4.  0.  0 /  4.  0.  0\n",
            "  libswscale      5.  5.100 /  5.  5.100\n",
            "  libswresample   3.  5.100 /  3.  5.100\n",
            "  libpostproc    55.  5.100 / 55.  5.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/content/drive/MyDrive/output_file_noaudio.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2mp41\n",
            "    encoder         : Lavf59.27.100\n",
            "  Duration: 00:01:00.38, start: 0.000000, bitrate: 1595 kb/s\n",
            "    Stream #0:0(und): Video: mpeg4 (Simple Profile) (mp4v / 0x7634706D), yuv420p, 640x360 [SAR 1:1 DAR 16:9], 1594 kb/s, 24 fps, 24 tbr, 12288 tbn, 24 tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : VideoHandler\n",
            "\u001b[1;31m./temp/audio.mkv: No such file or directory\n",
            "\u001b[0mAudio transfer failed. Interpolated video will have no audio\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "byKkkXq3rxr9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}